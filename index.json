
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":["何怡"],"categories":null,"content":"何怡，上海交通大学网络空间安全学院博士研究生，在王士林教授的指导下，当前主要研究方向为基于唇语特征的内容识别和身份认证。\n曾担任网络信息安全概论和人工智能导论课程助教。\n","date":1709337600,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1709337600,"objectID":"b8e4c386b67403a54b175459a72713de","permalink":"https://sjtuaiseclab.github.io/author/%E4%BD%95%E6%80%A1/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E4%BD%95%E6%80%A1/","section":"authors","summary":"","tags":null,"title":"何怡","type":"authors"},{"authors":["王晗亦"],"categories":null,"content":"王晗亦，上海交通大学网络空间安全学院博士研究生，当前主要研究方向为AI生成多媒体内容取证。\n","date":1709337600,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1709337600,"objectID":"2c9aa0954ef84ad480224f017e5f3aef","permalink":"https://sjtuaiseclab.github.io/author/%E7%8E%8B%E6%99%97%E4%BA%A6/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E7%8E%8B%E6%99%97%E4%BA%A6/","section":"authors","summary":"","tags":null,"title":"王晗亦","type":"authors"},{"authors":null,"categories":null,"content":"王士林，现任上海交通大学网络空间安全学院教授。主要从事多媒体信息分析与处理、多媒体信息内容安全、人工智能安全等方面的研究。\n近年来主持多项国家自然科学基金、上海市自然科学基金等项目，获得国家发明专利若干。在研究领域相关期刊和会议论文集中发表论文100多篇，论文SCI/Google Scholar累计引用1933次，个人h-Index为20。多次指导本科生参加全国大学生信息安全竞赛，获决赛一等奖和最具创新创业价值奖。\n","date":1709337600,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1709337600,"objectID":"4dff30e5aa4488e1508d42cab7132521","permalink":"https://sjtuaiseclab.github.io/author/%E7%8E%8B%E5%A3%AB%E6%9E%97/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E7%8E%8B%E5%A3%AB%E6%9E%97/","section":"authors","summary":"","tags":null,"title":"王士林","type":"authors"},{"authors":["杨磊"],"categories":null,"content":"杨磊，上海交通大学网络安全空间学院博士在读，导师为王士林教授，主要研究方向为唇语识别、唇语身份认证、语义分割等。\n曾获上海交通大学B等优秀奖学金、全国大学生信息安全竞赛一等奖、华为奖学金、“一流网安”奖学金等。\n","date":1709337600,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1709337600,"objectID":"ea6e95269c67691fc150d9cf47676128","permalink":"https://sjtuaiseclab.github.io/author/%E6%9D%A8%E7%A3%8A/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E6%9D%A8%E7%A3%8A/","section":"authors","summary":"","tags":null,"title":"杨磊","type":"authors"},{"authors":["李方圻"],"categories":null,"content":"李方圻，上海交通大学网络空间安全学院博士研究生，当前主要研究方向为人工智能系统的安全性。\n曾获得博士研究生国家奖学金、华为奖学金、小米奖学金、上海市优秀毕业生等荣誉，担任IEEE TDSC，TIFS，TNNLS，TFS，TAI，Pattern Recognition等期刊和AAAI等会议审稿人。\n","date":1709251200,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1709251200,"objectID":"7bcb994039f137de27375f79989f149b","permalink":"https://sjtuaiseclab.github.io/author/%E6%9D%8E%E6%96%B9%E5%9C%BB/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E6%9D%8E%E6%96%B9%E5%9C%BB/","section":"authors","summary":"","tags":null,"title":"李方圻","type":"authors"},{"authors":["闫超博"],"categories":null,"content":"闫超博，上海交通大学网络空间安全学院硕士研究生，导师为王士林教授。主要研究方向为深度学习模型版权保护、基于后门样本的模型水印、无数据依赖后门水印嵌入等。\n曾获上海市优秀毕业生、上海交通大学优秀学生干部、上海交通大学优秀团干部、上海交通大学优秀团员、全国大学生信息安全竞赛三等奖、宝钢教育奖学金、上海交通大学C等优秀奖学金等。曾任上海交通大学电子信息与电气工程学院双肩挑辅导员，曾获评上海交通大学优秀辅导员。\n","date":1709251200,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1709251200,"objectID":"78d043a1ee8e0cbc357d3efbbb472142","permalink":"https://sjtuaiseclab.github.io/author/%E9%97%AB%E8%B6%85%E5%8D%9A/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E9%97%AB%E8%B6%85%E5%8D%9A/","section":"authors","summary":"","tags":null,"title":"闫超博","type":"authors"},{"authors":["刘子涵"],"categories":null,"content":"刘子涵，上海交通大学网络空间安全学院硕士研究生，在王士林教授的指导下，当前主要研究方向为AI生成图像检测、深度伪造检测。\n曾获得数学建模国赛一等奖、校级A类奖学金、上海交通大学优秀毕业生等荣誉。\n","date":1683158400,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1683158400,"objectID":"3859cff2e9443ebbb974e9cd29d77682","permalink":"https://sjtuaiseclab.github.io/author/%E5%88%98%E5%AD%90%E6%B6%B5/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%88%98%E5%AD%90%E6%B6%B5/","section":"authors","summary":"","tags":null,"title":"刘子涵","type":"authors"},{"authors":null,"categories":null,"content":"段苏峰，上海交通大学网络空间安全学院助理研究员。2023年9月毕业于上海交通大学计算机科学与技术专业，获工学博士学位，2023年12月加入上海交通大学网络空间安全学院，现任助理研究员。研究方向为内容安全、自然语言处理、机器翻译等.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"610e3c49d2cbb4f6024f4f15a0475b30","permalink":"https://sjtuaiseclab.github.io/author/%E6%AE%B5%E8%8B%8F%E5%B3%B0/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E6%AE%B5%E8%8B%8F%E5%B3%B0/","section":"authors","summary":"","tags":null,"title":"段苏峰","type":"authors"},{"authors":null,"categories":null,"content":"黄林庆，上海交通大学网络空间安全学院助理研究员。研究方向为低质数据挖掘与学习、遥感影像智能解译、人工智能安全及应用等。在IEEE TCYB/TNNLS/TAI、INFFUS、SCIS、PR、KBS、CJA等国内外知名学术期刊和会议上发表论文10余篇，其中两篇文章入选了ESI高被引论文，相关研究成果得到了国内外知名学者的持续关注和高度评价。\n在新加坡国立大学计算机学院访问交流一年，并与新加坡国立大学和澳大利亚格里菲斯大学保持密切的学术交流与合作。申获西北工业大学博士论文创新基金（重点）项目一项、西北工业大学研究生创新创意种子基金项目一项，获得2020年西北工业大学优秀硕士学位论文奖励，获得国家奖学金等其它奖励和荣誉20余项。担任IEEE TCYB/TNNLS/TFS/TSMC-S/TETCI/TCAS-I/FITEE等国内外知名期刊与会议的审稿人。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"c33a129d35354f2b82d5ddfd19738008","permalink":"https://sjtuaiseclab.github.io/author/%E9%BB%84%E6%9E%97%E5%BA%86/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E9%BB%84%E6%9E%97%E5%BA%86/","section":"authors","summary":"","tags":null,"title":"黄林庆","type":"authors"},{"authors":null,"categories":null,"content":"刘功申，上海交通大学网络空间安全学院教授、博导。2003年7月毕业于上海交通大学计算机系并获博士学位，2004年至今，于上海交通大学网络空间安全学院从事教学科研工作。2014年在亚利桑那州立大学访学一年。研究兴趣人工智能安全、自然语言理解、内容安全、恶意代码防范等。\n主持3项国家自然科学基金项目，1项“十二五”重大专项子课题，1项科技委专项（原H863项目），正在主持1个与“东方头条”的校企联合实验室项目以及若干企业合作项目。作为主要技术核心人员，参与“信息内容分析技术国家工程实验室”建设项目、973项目、自然基金重点项目、“十三五”国家科技攻关计划项目等10多项。获得上海市优秀教材一等奖2项，保密科学技术奖1项。指导全国大学生信息安全大赛获一等奖4项，优秀指导教师2项。获校级烛光奖一等奖、优秀教师二等奖、教书育人奖三等奖各1项。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"2527515d852dba996fa4a268fddf10f0","permalink":"https://sjtuaiseclab.github.io/author/%E5%88%98%E5%8A%9F%E7%94%B3/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%88%98%E5%8A%9F%E7%94%B3/","section":"authors","summary":"","tags":null,"title":"刘功申","type":"authors"},{"authors":["陆千禧"],"categories":null,"content":"陆千禧，上海交通大学网络空间安全学院硕士研究生，在王士林教授的指导下，当前主要研究方向为面向深度伪造攻击的唇语身份认证系统脆弱性研究。\n曾获得全国大学生信息安全竞赛三等奖，上海交通大学C类奖学金等荣誉。曾担任人工智能导论课程助教工作。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"5db8bcfa5bf9b36ccb322c92d1336a67","permalink":"https://sjtuaiseclab.github.io/author/%E9%99%86%E5%8D%83%E7%A6%A7/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E9%99%86%E5%8D%83%E7%A6%A7/","section":"authors","summary":"","tags":null,"title":"陆千禧","type":"authors"},{"authors":null,"categories":null,"content":"孟魁，上海交通大学网络空间安全学院高级实验师。1995年毕业于上海交通大学，2006年于复旦大学获理学博士学位，2010年和2014年分别至加州大学圣地亚哥分校UCSD和亚利桑那州立大学ASU做访问学者。研究方向主要为移动安全、数据安全和社会网络等。\n进入上海交通大学工作以来，主持并参与多项国家级、省部级科研项目及国家重点实验室开放课题等，在国内外重要学术期刊上发表20余篇学术论文。2008年获上海市科技进步二等奖，2016年获评上海交通大学优秀教师。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"724a3ff25cebcd06f5e479a968120231","permalink":"https://sjtuaiseclab.github.io/author/%E5%AD%9F%E9%AD%81/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%AD%9F%E9%AD%81/","section":"authors","summary":"","tags":null,"title":"孟魁","type":"authors"},{"authors":["张卓萌"],"categories":null,"content":"张卓萌，上海交通大学网络空间安全学院硕士研究生，在王士林教授的指导下，当前主要研究方向为模型版权保护、神经网络水印、AIGC溯源等。\n曾获得上海市奖学金、“一流网安”奖学金、校级优秀奖学金、全国大学生信息安全竞赛二等奖、优秀团员等荣誉。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"78f65509eb06a25d861ba198cbd073b8","permalink":"https://sjtuaiseclab.github.io/author/%E5%BC%A0%E5%8D%93%E8%90%8C/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%BC%A0%E5%8D%93%E8%90%8C/","section":"authors","summary":"","tags":null,"title":"张卓萌","type":"authors"},{"authors":null,"categories":null,"content":"张倬胜，上海交通大学网络空间安全学院长聘教轨助理教授。研究方向为自然语言处理、预训练语言模型、自主智能体及其安全。在TPAMI, ICLR, ACL, AAAI等顶级期刊会议发表论文超过50篇。3篇第一作者论文入选为AAAI和COLING最有影响力论文。\n研发的语言理解与推理系统在8项国际权威自然语言理解评测获得第一名。开源成果在GitHub开源社区获得超过8000星标。曾在日本国立情报研究机构（NICT）、澜舟科技、微软雷德蒙德研究院、亚马逊云科技实习或访问。获评2023世界人工智能大会云帆奖、全球 AI 华人百强学术新星、ACM SIGAI China优博奖、上海市优秀博士毕业生、上海交通大学学术之星、百度奖学金等。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"b5e8864a6b12f015a4e14281c4266be4","permalink":"https://sjtuaiseclab.github.io/author/%E5%BC%A0%E5%80%AC%E8%83%9C/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%BC%A0%E5%80%AC%E8%83%9C/","section":"authors","summary":"","tags":null,"title":"张倬胜","type":"authors"},{"authors":["章杭炜"],"categories":null,"content":"章杭炜，上海交通大学网络空间安全学院硕士研究生，当前主要研究方向为模型版权保护和深度神经网络水印。\n本科期间曾在王士林教授的指导下获得了第十五届全国大学生信息安全竞赛作品赛二等奖。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"deca746c5834ca9d5517ea3875a2cb10","permalink":"https://sjtuaiseclab.github.io/author/%E7%AB%A0%E6%9D%AD%E7%82%9C/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E7%AB%A0%E6%9D%AD%E7%82%9C/","section":"authors","summary":"","tags":null,"title":"章杭炜","type":"authors"},{"authors":["何怡","杨磊","王晗亦","王士林"],"categories":null,"content":"","date":1709337600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1709337600,"objectID":"e9a1da5c860c74a1383eac82284a390b","permalink":"https://sjtuaiseclab.github.io/publication/conference/2024-icassp-heyi-speaker-adaptive-lipreading-via/","publishdate":"2024-03-02T00:00:00Z","relpermalink":"/publication/conference/2024-icassp-heyi-speaker-adaptive-lipreading-via/","section":"publication","summary":"Lipreading has been rapidly developed recently with the help of large-scale datasets and big models. Despite the significant progress made, the performance of lipreading models still falls short when dealing with unseen speakers. Therefore by analyzing the characteristics of speakers when uttering, we propose a novel parameter-efficient fine-tuning method based on spatio-temporal information learning. In our approach, a low-rank adaptation module that can influence global spatial features and a plug-and-play temporal adaptive weight learning module are designed in the front-end and back-end of the lipreading model, which can adapt to the speaker’s unique features such as the shape of the lips and the style of speech, respectively. An Adapter module is added between them to further enhance the spatio-temporal learning. The final experiments on the LRW-ID and GRID datasets demonstrate that our method achieves state-of-the-art performance even with fewer parameters.","tags":null,"title":"Speaker-Adaptive Lipreading via Spatio-Temporal Information Learning","type":"publication"},{"authors":["闫超博","李方圻","王士林"],"categories":null,"content":"","date":1709251200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1709251200,"objectID":"37919add73b52cfac7fe6ab67c3b6e45","permalink":"https://sjtuaiseclab.github.io/publication/conference/2024-icassp-yanchaobo-data-free-watermark-for/","publishdate":"2024-03-01T00:00:00Z","relpermalink":"/publication/conference/2024-icassp-yanchaobo-data-free-watermark-for/","section":"publication","summary":"Model watermarking secures ownership verification and copyright protection of deep neural networks. In the black-box scenario, watermarking schemes commonly rely on injecting triggers and requiring the model's training data to maintain its performance. However, such knowledge might be unavailable in commercial settings as model transactions or copyright transfers. To tackle this challenge, we propose a novel data-free black-box watermarking scheme. Our approach modifies data-free adversarial distillation to efficiently obtain a generator that produces samples serving as a substitute for the training data so the watermark can achieve high fidelity without referring to the training data.","tags":null,"title":"Data-Free Watermark for Deep Neural Networks by Truncated Adversarial Distillation","type":"publication"},{"authors":["李方圻","王士林"],"categories":null,"content":"","date":1708387200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1708387200,"objectID":"ef62e3647a2754365ae3066ac89d804d","permalink":"https://sjtuaiseclab.github.io/publication/conference/2024-aaai-lifangqi-revisiting-the-information-capacity/","publishdate":"2024-02-20T00:00:00Z","relpermalink":"/publication/conference/2024-aaai-lifangqi-revisiting-the-information-capacity/","section":"publication","summary":"To trace the copyright of deep neural networks, an owner can embed its identity information into its model as a watermark. The capacity of the watermark quantify the maximal volume of information that can be verified from the watermarked model. Current studies on capacity focus on the ownership verification accuracy under ordinary removal attacks and fail to capture the relationship between robustness and fidelity. This paper studies the capacity of deep neural network watermarks from an information theoretical perspective. We propose a new definition of deep neural network watermark capacity analogous to channel capacity, analyze its properties, and design an algorithm that yields a tight estimation of its upper bound under adversarial overwriting. We also propose a universal non-invasive method to secure the transmission of the identity message beyond capacity by multiple rounds of ownership verification. Our observations provide evidence for neural network owners and defenders that are curious about the tradeoff between the integrity of their ownership and the performance degradation of their products.","tags":null,"title":"Revisiting the Information Capacity of Neural Network Watermarks: Upper Bound Estimation and Beyond","type":"publication"},{"authors":null,"categories":null,"content":"","date":1706572800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1706572800,"objectID":"a7f24d70bac4934c63b2c0e0488757f3","permalink":"https://sjtuaiseclab.github.io/member/","publishdate":"2024-01-30T00:00:00Z","relpermalink":"/member/","section":"","summary":"","tags":null,"title":"教师名录","type":"landing"},{"authors":null,"categories":null,"content":"","date":1706572800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1706572800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://sjtuaiseclab.github.io/contact/","publishdate":"2024-01-30T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"联系我们","type":"landing"},{"authors":null,"categories":null,"content":"","date":1706572800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1706572800,"objectID":"94fee779d6493ad481b7c63f90b8b897","permalink":"https://sjtuaiseclab.github.io/student/","publishdate":"2024-01-30T00:00:00Z","relpermalink":"/student/","section":"","summary":"","tags":null,"title":"实验室成员","type":"landing"},{"authors":["杨磊","王士林"],"categories":null,"content":"","date":1690156800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1690156800,"objectID":"20e4ffb1cd586662638058661fccb4ef","permalink":"https://sjtuaiseclab.github.io/publication/journal/2023-tfs-yanglei-fine-grained-lip-image/","publishdate":"2023-07-24T00:00:00Z","relpermalink":"/publication/journal/2023-tfs-yanglei-fine-grained-lip-image/","section":"publication","summary":"Fine-grained lip image segmentation plays a critical role in downstream tasks such as automatic lipreading, as it enables the accurate identification of inner mouth components such as teeth and tongue which are essential for comprehending spoken utterances. However, achieving accurate and robust lip image segmentation in natural scenes is still challenging due to significant variations in lighting condition, head pose and background. This paper proposes a novel deep neural network based method for fine-grained lip image segmentation that exploits fuzzy and graph theories to handle these variations. A fuzzy learning module is designed to deal with the uncertainties in color and edge information and enhance feature maps at various scales. The fuzzy graph reasoning module with fuzzy projection models the relationship among semantics components and achieves a global receptive field. In our experiments, a fine-grained lip region segmentation dataset, i.e., FLRSeg, is built for evaluation and experiment results have shown that the proposed method can achieve superior segmentation performance (94.36% in pixel accuracy and 74.89% in mIoU) compared with several SOTA lip image segmentation methods.","tags":null,"title":"Fine-Grained Lip Image Segmentation using Fuzzy Logic and Graph Reasoning","type":"publication"},{"authors":["李方圻","王士林"],"categories":null,"content":"","date":1686009600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1686009600,"objectID":"d7ba589a16690e249b935a885b25c120","permalink":"https://sjtuaiseclab.github.io/publication/conference/2023-icassp-lifangqi-measure-and-countermeasure-of/","publishdate":"2023-06-06T00:00:00Z","relpermalink":"/publication/conference/2023-icassp-lifangqi-measure-and-countermeasure-of/","section":"publication","summary":"Backdoor-based watermarking schemes were proposed to protect the intellectual property of deep neural networks under the black-box setting. However, additional security risks emerge after the schemes have been published for as forensics tools. This paper reveals the capsulation attack that can easily invalidate most established backdoor-based watermarking schemes without sacrificing the pirated model's functionality. By encapsulating the deep neural network with a filter, an adversary can block abnormal queries and reject the ownership verification. We propose a metric to measure a backdoor-based watermarking scheme's security against the capsulation attack, and design a new backdoor-based deep neural network watermarking scheme that is secure against the capsulation attack by inverting the encoding process.","tags":null,"title":"Measure and Countermeasure of the Capsulation Attack against Backdoor-based Deep Neural Network Watermarks","type":"publication"},{"authors":["郭子豪","王士林"],"categories":null,"content":"","date":1683244800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1683244800,"objectID":"9f20db5c7b7e3bca320d992464e09cd9","permalink":"https://sjtuaiseclab.github.io/publication/conference/2023-icassp-guozihao-content-insensitive-dynamic-lip/","publishdate":"2023-05-05T00:00:00Z","relpermalink":"/publication/conference/2023-icassp-guozihao-content-insensitive-dynamic-lip/","section":"publication","summary":"Recent research has shown that lip-based speaker authenti- cation system can achieve good authentication performance. However, with emerging deepfake technology, attackers can make high fidelity talking videos of a user, thus posing a great threat to these systems. Confronted with this threat, we pro- pose a new deep neural network for lip-based visual speaker authentication against human imposters and deepfake attacks. One dynamic enhanced block with context modeling scheme is designed to capture a user’s unique talking habit by learn- ing from his/her lip movement. Meanwhile, a cross-modality content-guided loss is designed to help extract discrimina- tive features when learning from different lip movement of a user uttering different content. This loss makes the proposed method insensitive to content variation. Experiments on the GRID dataset show that the proposed method not only out- performs three state-of-the-art methods but also simplifies the training process and reduces the training cost.","tags":null,"title":"Content-Insensitive Dynamic Lip Feature Extraction for Visual Speaker Authentication against Deepfake Attacks","type":"publication"},{"authors":["张凯旋","刘子涵","胡嘉尚","王士林"],"categories":null,"content":"","date":1683158400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1683158400,"objectID":"85f4c5c7dbeb6a2fd71b33f0db3c7a7c","permalink":"https://sjtuaiseclab.github.io/publication/conference/2023-icassp-zhangkaixuan-an-auto-encoder-based/","publishdate":"2023-05-04T00:00:00Z","relpermalink":"/publication/conference/2023-icassp-zhangkaixuan-an-auto-encoder-based/","section":"publication","summary":"Camera fingerprint links a picture to its camera sensor, which is widely applied in sensor device identification, social network tracing and forgery detection. However, such fingerprints are in high dimensionality and cost substantial memory and computing resources, limiting their uses in real-time processing on embedded devices. In this paper, we introduce a new method to compress high-dimensional floating-point fingerprints to low-dimensional binary features to save storage as well as maintaining their representative abilities. Also, we present a much faster approach to sensor device matching with hamming distance, compared with the commonly used Peak to Correlation Energy (PCE) distance. Our method contains two stages. First, raw fingerprints are compressed into low-dimensional features with our proposed grouping strategy and auto-encoder based model. Then, the compressed floating-point features are further converted into more compact binary features. Experiments show that our method achieves superior performance over several competitive compression methods in both identification and verification tasks.","tags":null,"title":"An Auto-Encoder Based Method for Camera Fingerprint Compression","type":"publication"},{"authors":["李方圻","王士林"],"categories":null,"content":"","date":1680134400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1680134400,"objectID":"1641924299c3375543d0b16bac1430ef","permalink":"https://sjtuaiseclab.github.io/publication/journal/2023-tifs-lifangqi-linear-functionality-equivalence-attack/","publishdate":"2023-03-30T00:00:00Z","relpermalink":"/publication/journal/2023-tifs-lifangqi-linear-functionality-equivalence-attack/","section":"publication","summary":"As an ownership verification technique for deep neural networks, the white-box neural network watermark is being challenged by the functionality equivalence attack. By leveraging the structural symmetry within a deep neural network and manipulating the parameters accordingly, an adversary can invalidate almost all white-box watermarks without affecting the network's performance. This paper introduces the linear functionality equivalence attack, which can adapt to different network architectures without requiring knowledge of either the watermark or data. We also propose NeuronMap, a framework that can efficiently neutralize linear functionality equivalence attacks and can be easily combined with existing white-box watermarks to enhance their robustness. Experiments conducted on several deep neural networks and state-of-the-art white-box watermarking schemes have demonstrated not only the destructive power of linear functionality equivalence attacks but also the defense capability of NeuronMap. Our result shows that the threat of basic linear functionality equivalence attacks against deep neural network watermarks can be effectively solved using NeuronMap.","tags":null,"title":"Linear Functionality Equivalence Attack against Deep Neural Network Watermarks and a Defense Method by Neuron Mapping","type":"publication"},{"authors":["王晗亦","刘子涵","王士林"],"categories":null,"content":"","date":1674000000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1674000000,"objectID":"0305e15a430db66518bdb098ad78c746","permalink":"https://sjtuaiseclab.github.io/publication/journal/2023-tcsvt-wanghanyi-exploiting-complementary-dynamic-incoherence/","publishdate":"2023-01-18T00:00:00Z","relpermalink":"/publication/journal/2023-tcsvt-wanghanyi-exploiting-complementary-dynamic-incoherence/","section":"publication","summary":"Recently, manipulated videos based on DeepFake technology have spread widely on social media, causing concerns about the authenticity of video content and personal privacy pro- tection. Although existing DeepFake detection methods achieve remarkable progress in some specific scenarios, their detection performance usually drops drastically when detecting unseen manipulation methods. Compared with static information such as human face, dynamic information depicting the movements of facial features is more difficult to forge without leaving visual or statistical traces. Hence, in order to achieve better generalization ability, we focus on dynamic information analysis to disclose such traces and propose a novel Complementary Dynamic Interaction Network (CDIN). Inspired by the DeepFake detection methods based on mouth region analysis, both the global (entire face) and local (mouth region) dynamics are analyzed with properly designed network branches, respectively, and their feature maps at various levels are communicated with each other using a newly proposed Complementary Cross Dynamics Fusion Module (CCDFM). With CCDFM, the global branch will pay more attention to anomalous mouth movements and the local branch will gain more information about the global context. Finally, a multi-task learning scheme is designed to optimize the network with both the global and local information. Extensive experiments have demonstrated that our approach achieves better detection results compared with several SOTA methods, especially in detecting video forgeries manipulated by unseen methods.","tags":null,"title":"Exploiting Complementary Dynamic Incoherence for DeepFake Video Detection","type":"publication"},{"authors":["刘子涵","王晗亦","王士林"],"categories":null,"content":"","date":1670112000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1670112000,"objectID":"bfbf2363706693c5b10a4ccf08fa4835","permalink":"https://sjtuaiseclab.github.io/publication/conference/2022-accv-liuzihan-cross-domain-local-characteristic/","publishdate":"2022-12-04T00:00:00Z","relpermalink":"/publication/conference/2022-accv-liuzihan-cross-domain-local-characteristic/","section":"publication","summary":"As ultra-realistic face forgery techniques emerge, deepfake detection has attracted increasing attention due to security concerns. Many detectors cannot achieve accurate results when detecting unseen manipulations despite excellent performance on known forgeries. In this paper, we are motivated by the observation that the discrepancies between real and fake videos are extremely subtle and localized, and inconsistencies or irregularities can exist in some critical facial regions across various information domains. To this end, we propose a novel pipeline, Cross-Domain Local Forensics (XDLF), for more general deepfake video detection. In the proposed pipeline, a specialized framework is presented to simultaneously exploit local forgery patterns from space, frequency, and time domains, thus learning cross-domain features to detect forgeries. Moreover, the framework leverages four high-level forgery-sensitive local regions of a human face to guide the model to enhance subtle artifacts and localize potential anomalies. Extensive experiments on several benchmark datasets demonstrate the impressive performance of our method, and we achieve superiority over several state-of-the-art methods on cross-dataset generalization. We also examined the factors that contribute to its performance through ablations, which suggests that exploiting cross-domain local characteristics is a noteworthy direction for developing more general deepfake detectors.","tags":null,"title":"Cross-Domain Local Characteristic Enhanced Deepfake Video Detection","type":"publication"},{"authors":["李方圻","王士林"],"categories":null,"content":"","date":1648598400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1648598400,"objectID":"c5f240d5d20228e0f514dc2ff00288b7","permalink":"https://sjtuaiseclab.github.io/publication/journal/2022-tfs-lifangqi-online-intrusion-detection-for/","publishdate":"2022-03-30T00:00:00Z","relpermalink":"/publication/journal/2022-tfs-lifangqi-online-intrusion-detection-for/","section":"publication","summary":"The pervasive deployment of the internet of things (IoT) has significantly facilitated manufacturing and living. The diversity and continual updates of IoT systems make their security a crucial challenge, among which the detection of malicious network traffic turns out to be the most common yet destructive threat. Despite the efforts on feature engineering and classification backend designing, established intrusion detection systems sometimes lack robustness and are inflexible against the shift of the traffic distribution. To deal with these disadvantages, we design a fuzzy system for the online defense of IoT. Our framework incorporates a full Bayesian possibilistic clustering module for feature processing and an ensemble module motivated by reinforcement learning and adaptive boosting that dynamically fits the streaming data. The proposed clustering module overcomes the issue of determining the number of clusters and can dynamically identify new patterns. The classifier backend combines a collection of fuzzy decision trees that provide readable decision boundaries. The ensembled classifiers can accommodate the drift of data distribution to optimize the long-time performance. Our proposal is tested on settings including one dataset collected from real IoT systems and is compared to numerous competitors. Experimental results verified the advantage of our system regarding accuracy and stability.","tags":null,"title":"Online Intrusion Detection for IoT Systems with Full Bayesian Possibilistic Clustering and Ensembled Fuzzy Classifiers","type":"publication"}]